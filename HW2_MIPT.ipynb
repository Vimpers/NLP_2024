{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Домашнее задание №2 по предмету NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, GRU, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.utils import resample\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Чтение данных\n",
    "df = pd.read_csv(\"C:/Users/Petroo/Desktop/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Преобразовываем данные к строковому типу и заменяем NaN на пустые строки\n",
    "df['Text'] = df['Text'].astype(str)\n",
    "df['Text'] = df['Text'].fillna('')  # проверяем что нет пустых значений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Удаляем дубликаты\n",
    "df.drop_duplicates(subset='Text', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Очищаем данные и  приводим к нижнему регистру\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\d+', '', text)  \n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  \n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  \n",
    "    return text\n",
    "\n",
    "df['Text'] = df['Text'].apply(clean_text)  # Применяем очистку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Балансируем классы с использованием ресэмплинга\n",
    "df_majority = df[df['Sentiment'] == 'Neutral']\n",
    "df_minority_negative = df[df['Sentiment'] == 'Negative']\n",
    "df_minority_positive = df[df['Sentiment'] == 'Positive']\n",
    "\n",
    "df_minority_negative_upsampled = resample(df_minority_negative, replace=True, n_samples=len(df_majority), random_state=42)\n",
    "df_minority_positive_upsampled = resample(df_minority_positive, replace=True, n_samples=len(df_majority), random_state=42)\n",
    "\n",
    "# Создаем сбалансированный набор данных\n",
    "df_balanced = pd.concat([df_majority, df_minority_negative_upsampled, df_minority_positive_upsampled])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подготовка текстовых данных и целевых меток\n",
    "X = df_balanced['Text'].values\n",
    "y = df_balanced['Sentiment'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Кодируем целевые метки с использованием LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Токенизируем текст и приводим к фиксированной длине\n",
    "MAX_LEN = 100  \n",
    "tokenizer = Tokenizer(num_words=20000, oov_token=\"<OOV>\")  \n",
    "tokenizer.fit_on_texts(X)\n",
    "X_sequences = tokenizer.texts_to_sequences(X)  \n",
    "X_padded = pad_sequences(X_sequences, maxlen=MAX_LEN, padding='post')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Делим данные на  обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_padded, y_encoded, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определение моделей \n",
    "def create_lstm_model(max_vocab_size, max_len, num_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=max_vocab_size + 1, output_dim=128))  # Слой Embedding\n",
    "    model.add(Bidirectional(LSTM(64)))  # Bidirectional LSTM слой\n",
    "    model.add(Dropout(0.5))  # Dropout для предотвращения переобучения\n",
    "    model.add(Dense(num_classes, activation='softmax'))  # Полносвязный слой для классификации\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])  # Компиляция модели\n",
    "    return model\n",
    "\n",
    "def create_gru_model(max_vocab_size, max_len, num_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=max_vocab_size + 1, output_dim=128))\n",
    "    model.add(Bidirectional(GRU(64)))  # Bidirectional GRU слой\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def create_bilstm_model(max_vocab_size, max_len, num_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=max_vocab_size + 1, output_dim=128))\n",
    "    model.add(Bidirectional(LSTM(64)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучение моделей\n",
    "num_classes = len(label_encoder.classes_)  \n",
    "models = {\n",
    "    'LSTM': create_lstm_model(len(tokenizer.word_index), MAX_LEN, num_classes),\n",
    "    'GRU': create_gru_model(len(tokenizer.word_index), MAX_LEN, num_classes),\n",
    "    'Bidirectional LSTM': create_bilstm_model(len(tokenizer.word_index), MAX_LEN, num_classes)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обучение модели LSTM...\n",
      "Epoch 1/10\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 98ms/step - accuracy: 0.4785 - loss: 0.9959 - val_accuracy: 0.7202 - val_loss: 0.6970\n",
      "Epoch 2/10\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 99ms/step - accuracy: 0.8351 - loss: 0.4757 - val_accuracy: 0.7893 - val_loss: 0.5846\n",
      "Epoch 3/10\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 98ms/step - accuracy: 0.9117 - loss: 0.2690 - val_accuracy: 0.7915 - val_loss: 0.6047\n",
      "Epoch 4/10\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 98ms/step - accuracy: 0.9421 - loss: 0.1815 - val_accuracy: 0.7958 - val_loss: 0.7132\n",
      "Epoch 5/10\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 99ms/step - accuracy: 0.9646 - loss: 0.1080 - val_accuracy: 0.8017 - val_loss: 0.7591\n",
      "Epoch 6/10\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 97ms/step - accuracy: 0.9748 - loss: 0.0850 - val_accuracy: 0.7915 - val_loss: 0.9614\n",
      "Epoch 7/10\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 98ms/step - accuracy: 0.9818 - loss: 0.0630 - val_accuracy: 0.7958 - val_loss: 0.9537\n",
      "Epoch 8/10\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 99ms/step - accuracy: 0.9861 - loss: 0.0494 - val_accuracy: 0.7936 - val_loss: 1.0380\n",
      "Epoch 9/10\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 99ms/step - accuracy: 0.9905 - loss: 0.0346 - val_accuracy: 0.7801 - val_loss: 1.0522\n",
      "Epoch 10/10\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 101ms/step - accuracy: 0.9907 - loss: 0.0330 - val_accuracy: 0.7693 - val_loss: 1.2026\n",
      "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step\n",
      "LSTM Accuracy: 0.7709098768100281\n",
      "LSTM F1 Score: 0.7704608364427223\n",
      "Обучение модели GRU...\n",
      "Epoch 1/10\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 104ms/step - accuracy: 0.4500 - loss: 1.0184 - val_accuracy: 0.7310 - val_loss: 0.6739\n",
      "Epoch 2/10\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 102ms/step - accuracy: 0.8357 - loss: 0.4802 - val_accuracy: 0.7807 - val_loss: 0.5840\n",
      "Epoch 3/10\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 102ms/step - accuracy: 0.9148 - loss: 0.2609 - val_accuracy: 0.7898 - val_loss: 0.6584\n",
      "Epoch 4/10\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 104ms/step - accuracy: 0.9458 - loss: 0.1647 - val_accuracy: 0.7888 - val_loss: 0.7060\n",
      "Epoch 5/10\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 102ms/step - accuracy: 0.9647 - loss: 0.1075 - val_accuracy: 0.7909 - val_loss: 0.8792\n",
      "Epoch 6/10\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 103ms/step - accuracy: 0.9778 - loss: 0.0715 - val_accuracy: 0.7861 - val_loss: 0.8838\n",
      "Epoch 7/10\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 100ms/step - accuracy: 0.9834 - loss: 0.0546 - val_accuracy: 0.7650 - val_loss: 1.1810\n",
      "Epoch 8/10\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 102ms/step - accuracy: 0.9855 - loss: 0.0425 - val_accuracy: 0.7807 - val_loss: 1.1460\n",
      "Epoch 9/10\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 102ms/step - accuracy: 0.9919 - loss: 0.0252 - val_accuracy: 0.7812 - val_loss: 1.3743\n",
      "Epoch 10/10\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 101ms/step - accuracy: 0.9894 - loss: 0.0325 - val_accuracy: 0.7753 - val_loss: 1.4397\n",
      "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step\n",
      "GRU Accuracy: 0.7817160146963475\n",
      "GRU F1 Score: 0.7818124982703244\n",
      "Обучение модели Bidirectional LSTM...\n",
      "Epoch 1/10\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 102ms/step - accuracy: 0.4819 - loss: 0.9845 - val_accuracy: 0.7088 - val_loss: 0.7135\n",
      "Epoch 2/10\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 98ms/step - accuracy: 0.8074 - loss: 0.5268 - val_accuracy: 0.7877 - val_loss: 0.5878\n",
      "Epoch 3/10\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 103ms/step - accuracy: 0.9043 - loss: 0.2879 - val_accuracy: 0.7769 - val_loss: 0.6482\n",
      "Epoch 4/10\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 103ms/step - accuracy: 0.9465 - loss: 0.1667 - val_accuracy: 0.7990 - val_loss: 0.6998\n",
      "Epoch 5/10\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 96ms/step - accuracy: 0.9607 - loss: 0.1220 - val_accuracy: 0.7855 - val_loss: 0.8220\n",
      "Epoch 6/10\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 96ms/step - accuracy: 0.9731 - loss: 0.0895 - val_accuracy: 0.7861 - val_loss: 0.9466\n",
      "Epoch 7/10\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 96ms/step - accuracy: 0.9804 - loss: 0.0629 - val_accuracy: 0.7666 - val_loss: 1.0180\n",
      "Epoch 8/10\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 96ms/step - accuracy: 0.9871 - loss: 0.0438 - val_accuracy: 0.7780 - val_loss: 1.0975\n",
      "Epoch 9/10\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 96ms/step - accuracy: 0.9913 - loss: 0.0318 - val_accuracy: 0.7682 - val_loss: 1.2240\n",
      "Epoch 10/10\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 96ms/step - accuracy: 0.9861 - loss: 0.0478 - val_accuracy: 0.7915 - val_loss: 1.2673\n",
      "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step\n",
      "Bidirectional LSTM Accuracy: 0.7944672574022045\n",
      "Bidirectional LSTM F1 Score: 0.7943969280894562\n"
     ]
    }
   ],
   "source": [
    "# Оценка моделей\n",
    "results = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f'Обучение модели {model_name}...')\n",
    "    history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.1)  # Обучение модели\n",
    "    \n",
    "    # Оценка модели\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)  # Преобразуем предсказания в классы\n",
    "    accuracy = accuracy_score(y_test, y_pred_classes)  # Точность\n",
    "    f1 = f1_score(y_test, y_pred_classes, average='weighted')  # F1-score\n",
    "    \n",
    "    results[model_name] = {'Accuracy': accuracy, 'F1 Score': f1}  # Сохраняем результат\n",
    "    print(f'{model_name} Accuracy: {accuracy}')\n",
    "    print(f'{model_name} F1 Score: {f1}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Результаты всех моделей:\n",
      "LSTM: Accuracy = 0.7709098768100281, F1 Score = 0.7704608364427223\n",
      "GRU: Accuracy = 0.7817160146963475, F1 Score = 0.7818124982703244\n",
      "Bidirectional LSTM: Accuracy = 0.7944672574022045, F1 Score = 0.7943969280894562\n"
     ]
    }
   ],
   "source": [
    "# Вывод результатов для всех моделей\n",
    "print(\"\\nРезультаты всех моделей:\")\n",
    "for model_name, metrics in results.items():\n",
    "    print(f\"{model_name}: Accuracy = {metrics['Accuracy']}, F1 Score = {metrics['F1 Score']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вывод\n",
    "\n",
    "В процессе решения задачи классификации тональности текста были обучены и сравнены различные подходы: классические модели машинного обучения, эвристические методы, и RNN.\n",
    "\n",
    "Эвристические методы\n",
    "\n",
    "Данный подход может показать адекватные результаты для небольших задач или в случае ограниченного объема данных, его эффективность оказалась значительно ниже по сравнению с машинным обучением. Главным недостатком является не учёт контекста и сложных зависимостей в тексте.\n",
    "\n",
    "Классические модели машинного обучения\n",
    "\n",
    "Результаты по сравнению с эвристикой получились лучше, благодаря использованию методов векторизации текста, таких как TF-IDF, но эти модели также имеют ограничения в части более сложных языковых конструкций и синтаксиса.\n",
    "\n",
    "Рекуррентные нейронные сети (RNN)\n",
    "\n",
    "RNN (LSTM, GRU и Bidirectional LSTM) показали наилучшие результаты, так как они способны учитывать порядок слов, контекст и долгосрочные зависимости в тексте. Эти модели обучались на токенизированных данных, что позволило захватить сложные зависимости между словами, и их производительность была значительно выше по сравнению с эвристиками и классическими моделями.\n",
    "Несмотря на то, что LSTM и GRU показали близкие результаты, Bidirectional LSTM позволила моделям более точно учитывать и обратный контекст, что важно может быть важно для некоторых типов текстов.\n",
    "\n",
    "RNN продемонстрировали наибольшую точность по сравнению с эвристиками и классическими моделями машинного обучения, учитывая их способность обрабатывать последовательные данные и учитывать длинные зависимости в тексте. \n",
    "Но для них потребовалось гораздо больше вычислительных ресурсов и времени на обучение.\n",
    "\n",
    "Эвристические методы могут быть полезны в условиях ограниченных вычислительных мощностей или быстрого анализа, но они очень уступают современным методам. Классические модели машинного обучения обеспечивают баланс между скоростью и точностью, но с усложнением данных RNN оказываются наиболее эффективным решением."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
